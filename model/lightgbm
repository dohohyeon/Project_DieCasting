# lightGBM

import pandas as pd
import numpy as np

from sklearn.impute import KNNImputer, SimpleImputer
from sklearn.preprocessing import OrdinalEncoder, RobustScaler, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from lightgbm import LGBMClassifier
from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# -------------------
# 0) 데이터 불러오기 & 전처리
# -------------------
df = pd.read_csv("./data/train.csv")

# 이상치/결측 행 제거
df = df.drop(index=19327) 
df = df.drop(index=[6000,11811,17598]) 
df = df.drop(index=[46546])
df = df.drop(index=list(df[df['Coolant_temperature'] == 1449].index))
df = df.drop(index=list(df[df['upper_mold_temp1'] == 1449].index))
df = df.drop(index=list(df[df['upper_mold_temp2'] == 4232].index))

# 시간 변수 가공
df['registration_time'] = pd.to_datetime(df['registration_time'])
df['hour'] = df['registration_time'].dt.hour.astype(object)

# 결측치 보정
df['tryshot_signal'] = df['tryshot_signal'].fillna('A')
df['molten_volume'] = df['molten_volume'].fillna(0)
condition = (df['molten_volume'].notna()) & (df['heating_furnace'].isna())
df.loc[condition, 'heating_furnace'] = 'C'

# 타입 변경
df["mold_code"] = df["mold_code"].astype(object)
df["EMS_operation_time"] = df["EMS_operation_time"].astype(object)

# 값 조건 기반 결측 처리
df.loc[df["molten_temp"] <= 80, "molten_temp"] = np.nan
df.loc[df["physical_strength"] <= 5, "physical_strength"] = np.nan

# 불필요한 컬럼 제거
df = df.drop(columns=[
    'id','line','name','mold_name','emergency_stop','time','date','registration_time',
    'upper_mold_temp3','lower_mold_temp3','working'
])
df.info()

df.to_csv("train_df.csv")
# -------------------
# 1) X, y 분리
# -------------------
y = df['passorfail']
X = df.drop(columns=['passorfail'])

# 시간 순서 기준으로 split 
split_point = int(len(df) * 0.8)
X_train, X_test = X.iloc[:split_point], X.iloc[split_point:]
y_train, y_test = y.iloc[:split_point], y.iloc[split_point:]

# -------------------
# 2) 수치/범주형 컬럼 분리
# -------------------
num_cols = X.select_dtypes(include=['int64','float64']).columns
cat_cols = X.select_dtypes(include=['object']).columns

# -------------------
# 3) 전처리기 정의
# -------------------
# 수치형: KNN으로 결측치 채우기
num_transformer = Pipeline(steps=[
    ('imputer', KNNImputer(n_neighbors=5)),
    ('scaler', RobustScaler())
])

# 범주형: 최빈값 + OrdinalEncoder
cat_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))
])

# ColumnTransformer로 합치기
# preprocessor = ColumnTransformer(
#     transformers=[
#         ('num', num_transformer, num_cols),
#         ('cat', cat_transformer, cat_cols)
#     ]
# )


preprocessor = ColumnTransformer(
    transformers=[
        ('num', num_transformer, num_cols),
        ('cat', cat_transformer, cat_cols)
    ],
    verbose_feature_names_out=False   # 👈 prefix 제거
)




# -------------------
# 4) LightGBM 모델
# -------------------
model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', LGBMClassifier(random_state=42))
])




# -------------------
# 5) 학습 & 평가
# -------------------
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
y_prob = model.predict_proba(X_test)[:, 1]

# Classification Report
print("Classification Report:")
print(classification_report(y_test, y_pred))

# ROC-AUC
print("ROC-AUC:", roc_auc_score(y_test, y_prob))

# Confusion Matrix 시각화
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False,
            xticklabels=["Pred 0","Pred 1"],
            yticklabels=["True 0","True 1"])
plt.title("Confusion Matrix")
plt.ylabel("True Label")
plt.xlabel("Predicted Label")
plt.show()


import optuna
from sklearn.metrics import roc_auc_score

def objective(trial):
    params = {
    "num_leaves": trial.suggest_int("num_leaves", 16, 256),
    "max_depth": trial.suggest_int("max_depth", 3, 12),
    "learning_rate": trial.suggest_float("learning_rate", 1e-3, 0.3, log=True),
    "n_estimators": trial.suggest_int("n_estimators", 100, 1000),
    "subsample": trial.suggest_float("subsample", 0.6, 1.0),
    "colsample_bytree": trial.suggest_float("colsample_bytree", 0.6, 1.0),
    "min_child_samples": trial.suggest_int("min_child_samples", 5, 100),
    "scale_pos_weight": (len(y_train) - y_train.sum()) / y_train.sum(),
    "min_gain_to_split": 0.0   # 분할 허용을 더 느슨하게
}


    model = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', LGBMClassifier(random_state=42, **params))
    ])
    model.fit(X_train, y_train)
    y_prob = model.predict_proba(X_test)[:, 1]
    return roc_auc_score(y_test, y_prob)

# 실행
study = optuna.create_study(direction="maximize")
study.optimize(objective, n_trials=30, show_progress_bar=True)

print("Best Trial:")
best_trial = study.best_trial
print("ROC-AUC:", best_trial.value)
print("Best Params:", best_trial.params)


best_trial={'num_leaves': 98, 'max_depth': 9, 'learning_rate': 0.008275183434186801, 'n_estimators': 677, 'subsample': 0.6035915042464275, 'colsample_bytree': 0.879104309394895, 'min_child_samples': 85,
            'scale_pos_weight':21.583812811660913}


# 최적 파라미터로 최종 모델 재학습
final_model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', LGBMClassifier(random_state=42, **best_trial))
])
final_model.fit(X_train, y_train)

# 최종 feature 이름 확인
feature_names = final_model.named_steps['preprocessor'].get_feature_names_out()
print(feature_names)
